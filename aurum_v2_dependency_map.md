# Aurum Legacy â†’ v2 Dependency Map

> Complete mapping of every `raise NotImplementedError` stub in `aurum_v2/` to
> the legacy file and function that contains the real implementation.
>
> **Last updated:** 2026-02-18

---

## Key

| Symbol | Meaning |
|--------|---------|
| âœ… | Already implemented in v2 |
| ðŸ”´ | Stub â€” needs porting from legacy Python |
| ðŸŸ£ | Stub â€” needs reimplementation from legacy Java (no Python source) |
| âšª | Not needed for the agent use case |

---

## 1  `aurum_v2/store/elastic_store.py`

> **Legacy source**: `aurum_legacy/modelstore/elasticstore.py` (class `StoreHandler`)

| v2 Method | Legacy Method | Status | Notes |
|---|---|---|---|
| `get_all_fields()` | `StoreHandler.get_all_fields_of_source()` | âœ… | ES scroll over `profile` index; yields (db, source, field, nid) |
| `get_all_fields_name()` | `StoreHandler.get_all_fields_name()` | âœ… | Added in bug-fix pass |
| `get_all_fields_of_source()` | `StoreHandler.get_all_fields_of_source()` | âœ… | Filtered by `sourceName` |
| `search_keywords()` | `StoreHandler.search_keywords()` | âœ… | Fuzzy ES search against `text` or `profile` index |
| `exact_search_keywords()` | `StoreHandler.exact_search_keywords()` | âœ… | ES `term` query variant |
| `bulk_insert_profiles()` | (new) | âœ… | ES `helpers.bulk` insertion |
| `get_profile()` | `StoreHandler.peek_values()` | âœ… | Point query on `profile` index |
| `suggest_field_names()` | `StoreHandler.suggest_field_names()` | âœ… | ES completion suggester |
| `StoreHandler` alias | â€” | âœ… | Backward-compat alias for api.py import |

---

## 2  `aurum_v2/discovery/algebra.py`

> **Legacy source**: `aurum_legacy/algebra.py` (class `Algebra`)

| v2 Method | Legacy Method | Status | Notes |
|---|---|---|---|
| `search()` | `Algebra.search()` | âœ… | Calls `store.search_keywords()`, wraps hits in DRS |
| `exact_search()` | `Algebra.exact_search()` | âœ… | Same pattern with `exact_search_keywords()` |
| `search_content()` | `Algebra.search_content()` | âœ… | Convenience wrapper |
| `search_attribute()` | `Algebra.search_attribute()` | âœ… | Convenience wrapper |
| `search_exact_attribute()` | `Algebra.search_exact_attribute()` | âœ… | Convenience wrapper |
| `search_table()` | `Algebra.search_table()` | âœ… | Convenience wrapper |
| `_neighbor_search()` | `Algebra.__neighbor_search()` | âœ… | Generalâ†’DRS, provenance carrier, expand table-mode, iterate neighbors |
| `content_similar_to()` | `Algebra.content_similar_to()` | âœ… | Wraps _neighbor_search(CONTENT_SIM) |
| `schema_similar_to()` | `Algebra.schema_similar_to()` | âœ… | Wraps _neighbor_search(SCHEMA_SIM) |
| `pkfk_of()` | `Algebra.pkfk_of()` | âœ… | Wraps _neighbor_search(PKFK) |
| `traverse()` | `Algebra.__traverse()` | âœ… | BFS with max_hops, proper frontier tracking |
| `paths()` | `Algebra.paths()` | âœ… | Cartesian product â†’ find_path_hit/find_path_table |
| `intersection()` | `Algebra.intersection()` | âœ… | Delegates to DRS.intersection() |
| `union()` | `Algebra.union()` | âœ… | Delegates to DRS.union() |
| `difference()` | `Algebra.difference()` | âœ… | Delegates to DRS.set_difference() |
| `make_drs()` | `Algebra.make_drs()` | âœ… | Handles list input (union fold) or single |
| `drs_from_table_hit()` | `Algebra.drs_from_table_hit()` | âœ… | Gets all hits from table + provenance |
| `_general_to_drs()` | `Algebra._general_to_drs()` | âœ… | Type-dispatch: DRS/None/int/str/tuple/Hit â†’ DRS |
| `_nid_to_hit()` | `Algebra._nid_to_hit()` | âœ… | nid â†’ Hit via network.get_info_for() |
| `_node_to_hit()` | `Algebra._node_to_hit()` | âœ… | (db, source, field) â†’ Hit |
| `_hit_to_drs()` | Inline in legacy | âœ… | Wraps Hit in DRS |
| `suggest_schema()` | `Algebra.suggest_schema()` | âšª | Not ported â€” low-value for agent |
| Metadata API | `Algebra.__annotate()`, `__md_search()`, etc. | âšª | Not needed â€” agent reasons semantically |

---

## 3  `aurum_v2/graph/field_network.py`

> **Legacy source**: `aurum_legacy/knowledgerepr/fieldnetwork.py` (class `FieldNetwork`)

| v2 Method | Legacy Method | Status | Notes |
|---|---|---|---|
| `init_meta_schema()` | `FieldNetwork.init_meta_schema()` | âœ… | Populates id_to_info, source_to_fields, adds nodes with cardinality |
| `add_relation()` | `FieldNetwork.add_field_relation()` | âœ… | Adds weighted edge to NetworkX graph under relation key |
| `get_info_for()` | `FieldNetwork.get_info_for()` | âœ… | nid â†’ (db, source, field, type) |
| `neighbors_id()` | `FieldNetwork.neighbors_id()` | âœ… | Iterates G[nid], filters by relation key, builds Hit list â†’ DRS |
| `find_path_hit()` | `FieldNetwork.find_path_hit()` | âœ… | DFS with max_hops; bug-fixed to use absorb() not absorb_provenance() |
| `find_path_table()` | `FieldNetwork.find_path_table()` | âœ… | Table-level DFS with tableâ†’fields expansion; bug-fixed |
| `enumerate_relation()` | `FieldNetwork.enumerate_relation()` | âœ… | Iterates all node pairs with a given relation type |
| `get_hits_from_table()` | `FieldNetwork.get_hits_from_table()` | âœ… | Returns all Hits for a table name |
| `get_cardinality()` | `FieldNetwork.get_cardinality()` | âœ… | Node attribute lookup |
| `fields_degree()` | `FieldNetwork.fields_degree()` | âœ… | Top-k nodes by degree |
| `graph_order()` | `FieldNetwork.graph_order()` | âœ… | Number of nodes |
| `get_number_tables()` | (derived) | âœ… | len(source_to_fields) |
| `serialize()` | `FieldNetwork.serialize()` | âœ… | Pickles graph + dicts via io_utils |
| `deserialize_network()` | `FieldNetwork.deserialize()` | âœ… | Unpickle, reconstruct FieldNetwork |
| `iterate_ids()` / `iterate_values()` | `FieldNetwork.iterate_ids()` | âœ… | Generators yielding (db, source, field, type) |
| `md_neighbors_id()` | `FieldNetwork.md_neighbors_id()` | âšª | Metadata-relation traversal â€” not needed for agent |

---

## 4  `aurum_v2/builder/network_builder.py`

> **Legacy source**: `aurum_legacy/knowledgerepr/networkbuilder.py` (module-level functions)

| v2 Method | Legacy Function | Status | Notes |
|---|---|---|---|
| `build_schema_sim_relation()` | `networkbuilder.build_schema_sim_relation()` | âœ… | TF-IDF on field names â†’ NearPy LSH â†’ SCHEMA_SIM edges. Bug-fixed: cached dense vectors. |
| `build_content_sim_mh_text()` | `networkbuilder.build_content_sim_mh_text()` | âœ… | MinHash objects â†’ DataSketch LSH â†’ CONTENT_SIM edges |
| `build_content_sim_num_overlap()` | `networkbuilder.build_content_sim_num_overlap()` | âœ… | IQR overlap + DBSCAN clustering. Bug-fixed: early break optimization. |
| `build_pkfk_relation()` | `networkbuilder.build_pkfk_relation()` | âœ… | Cardinality > threshold â†’ INCLUSION_DEP/CONTENT_SIM neighbors â†’ PKFK edge |

---

## 5  `aurum_v2/builder/analysis.py`

> **Legacy source**: `aurum_legacy/dataanalysis/dataanalysis.py` (module-level functions)
>
> **Status**: ðŸ”´ ALL 13 FUNCTIONS ARE STUBS. Signatures + docstrings are correct; bodies all `raise NotImplementedError`.

| v2 Stub Method | Legacy Function | Status |
|---|---|---|
| `get_tfidf_docs()` | `dataanalysis.get_tfidf_docs()` | ðŸ”´ |
| `cosine_similarity_matrix()` | `dataanalysis.cosine_similarity_matrix()` | ðŸ”´ |
| `build_dict_values()` | `dataanalysis.build_dict_values()` | ðŸ”´ |
| `compute_overlap()` | `dataanalysis.compute_overlap()` | ðŸ”´ |
| `compute_overlap_of_columns()` | `dataanalysis.compute_overlap_of_columns()` | ðŸ”´ |
| `compare_num_columns_dist_ks()` | `dataanalysis.compare_num_columns_dist_ks()` | ðŸ”´ |
| `compare_pair_num_columns()` | `dataanalysis.compare_pair_num_columns()` | ðŸ”´ |
| `compare_pair_text_columns()` | `dataanalysis.compare_pair_text_columns()` | ðŸ”´ |
| `compare_text_columns_cosine()` | `dataanalysis.compare_text_columns_dist()` | ðŸ”´ |
| `get_numerical_signature()` | `dataanalysis.get_numerical_signature()` | ðŸ”´ |
| `get_textual_signature()` | `dataanalysis.get_textual_signature()` | ðŸ”´ |
| `get_sim_matrix_numerical()` | `dataanalysis.get_sim_matrix_numerical()` | ðŸ”´ |
| `get_sim_matrix_text()` | `dataanalysis.get_sim_matrix_text()` | ðŸ”´ |

> **Note**: `network_builder.py` is fully implemented but does NOT currently call these analysis.py functions â€” it inlines its own TF-IDF/MinHash/IQR logic. These functions are for future DoD-level column comparison and diagnostics.

---

## 6  `aurum_v2/dod/dod.py`

> **Legacy source**: `aurum_legacy/DoD/dod.py` (class `DoD`)

| v2 Method | Legacy Method | Status | Notes |
|---|---|---|---|
| `FilterType` enum | `FilterType` | âœ… | ATTR / CELL |
| `ViewSearchPredicate` | `FilterItem` | âœ… | NamedTuple with filter, col_name, keyword |
| `individual_filters()` | `DoD.individual_filters()` | ðŸ”´ | `search_exact_attribute` for ATTR, `search_content` for CELL |
| `joint_filters()` | `DoD.joint_filters()` | ðŸ”´ | If cell empty â†’ attr only; else intersect attrâˆ©content DRS |
| `virtual_schema_iterative_search()` | `DoD.virtual_schema_iterative_search()` | ðŸ”´ | 5-stage pipeline (~440 lines in legacy) |
| `_eager_candidate_exploration()` | Nested in `virtual_schema_iterative_search` | ðŸ”´ | Greedy filter-coverage enumeration |
| `joinable()` | `DoD.joinable()` | ðŸ”´ | Pairwise paths â†’ product â†’ dedup â†’ sort by joins |
| `transform_join_path_to_pair_hop()` | `DoD.transform_join_path_to_pair_hop()` | ðŸ”´ | Linear path â†’ (src,trg) pairs |
| `compute_join_graph_id()` | `DoD.compute_join_graph_id()` | ðŸ”´ | Sum of nid for all hops |
| `is_join_graph_materializable()` | `DoD.is_join_graph_materializable()` | ðŸ”´ | Per-hop CSV read + filter + join + row check |
| `materialize_join_graphs()` | `DoD.materialize_join_graphs()` | ðŸ”´ | For each jg: materialize + format |
| `format_join_graph_into_nodes_edges()` | `DoD.format_join_graph_into_nodes_edges()` | ðŸ”´ | Builds `{nodes, edges}` dict |
| `rank_join_graphs_by_key()` | Module-level | ðŸ”´ | Score join graphs by key quality |
| `rank_fields_in_join_path()` | Module-level | ðŸ”´ | Per-hop field ranking |
| `get_paths_for_tables()` | Module-level | ðŸ”´ | Resolve filesystem paths for table nids |

---

## 7  `aurum_v2/dod/join_utils.py`

> **Legacy source**: `aurum_legacy/DoD/utils.py` + `aurum_legacy/DoD/data_processing_utils.py`

| v2 Method | Legacy Function | Status | Notes |
|---|---|---|---|
| `InTreeNode` class | `InTreeNode` | âœ… | Identical to legacy |
| `configure_csv_separator()` | Module state | âœ… | Sets `SEP` / `LINES_TO_READ` globals |
| `read_relation()` | `utils.get_dataframe()` | ðŸ”´ | `pd.read_csv()` with caching |
| `read_relation_on_copy()` | `utils.get_dataframe_copy()` | ðŸ”´ | Cache read, return `.copy()` |
| `read_relation_no_cache()` | `utils.get_dataframe_nocache()` | ðŸ”´ | Simple `pd.read_csv()`, no cache |
| `apply_filter()` | `utils.get_dataframe_with_filter()` | ðŸ”´ | Read + lowercase/strip + filter rows |
| `get_filter_columns()` | `utils.get_filter_columns()` | ðŸ”´ | Extract column names by FilterType |
| `normalize_key()` | `utils.normalize_for_join_spec()` | ðŸ”´ | `s.lower().strip()` |
| `join_ab_on_key()` | `utils.join_ab_on_key()` | ðŸ”´ | `pd.merge()` + key normalization |
| `estimate_row_size()` | `utils.estimate_row_size()` | ðŸ”´ | Memory usage / rows |
| `estimate_join_memory()` | `utils.estimate_join_memory()` | ðŸ”´ | Estimated rows Ã— row_size vs limit |
| `join_ab_on_key_optimizer()` | `utils.join_ab_on_key_optimizer()` | ðŸ”´ | Chunked join, 3-min timeout, spill-to-disk |
| `_build_tree()` | Nested in `materialize_join_graph()` | ðŸ”´ | Parent-child tree from join hops |
| `_fields_for_hop()` | Nested in `materialize_join_graph()` | ðŸ”´ | Resolve field names for (l,r) pair |
| `materialize_join_graph()` | `utils.materialize_join_graph()` | ðŸ”´ | Tree-fold: build in-tree â†’ join leaves â†’ root |
| `materialize_join_graph_filtered()` | `utils.materialize_join_graph_with_filters()` | ðŸ”´ | Same + `apply_filter()` before each join |
| `sample_by_key()` | `utils.sample_by_key()` | ðŸ”´ | Deterministic hash-based ID sampling |

---

## 8  `aurum_v2/dod/view_analysis.py`

> **Legacy source**: `aurum_legacy/DoD/material_view_analysis.py` (module-level functions)

| v2 Method | Legacy Function | Status | Notes |
|---|---|---|---|
| `ViewClass` enum | `ViewClass` | âœ… | EQUIVALENT / CONTAINED / COMPLEMENTARY / CONTRADICTORY |
| `most_likely_key()` | `most_likely_key()` | ðŸ”´ | Unique ratio sorted desc, return top column |
| `unique_ratio()` | `unique_ratio()` | ðŸ”´ | `nunique/len` per column |
| `curate()` | `curate()` | ðŸ”´ | dropna â†’ drop_duplicates â†’ sort axes |
| `equivalent()` | `equivalent()` | ðŸ”´ | Curate both, compare cardinality â†’ schema â†’ values |
| `contained()` | `contained()` | ðŸ”´ | Set difference of lowered values per column |
| `complementary()` | `complementary()` | ðŸ”´ | Symmetric diff of most-likely-key values |
| `contradictory_value_check()` | `contradictory()` | ðŸ”´ | Group by key, check nunique > 1 |
| `contradictory()` | `contradictory()` | ðŸ”´ | Row-level conflict detection |

---

## 9  `aurum_v2/models/drs.py`

> **Legacy source**: `aurum_legacy/api/apiutils.py` (class `DRS`)

| v2 Method | Legacy Method | Status | Notes |
|---|---|---|---|
| `__iter__()` / `__next__()` | `DRS.__iter__()` | âœ… | Bug-fixed: separate `_DRSIterator` class for safe nested iteration |
| `to_dict()` | `DRS.__dict__()` | âœ… | Bug-fixed: uses `_asdict()` not `asdict()` |
| `absorb()` | `DRS.absorb()` | âœ… | Set union + provenance merge |
| `absorb_provenance()` | `DRS.absorb_provenance()` | âœ… | Merge provenance graphs via nx.compose() |
| `intersection()` | `DRS.intersection()` | âœ… | Bug-fixed: TABLE mode now keeps all columns per table |
| `union()` | `DRS.union()` | âœ… | Set union + composed provenance |
| `set_difference()` | `DRS.set_difference()` | âœ… | Set diff + composed provenance |
| `why()` | `DRS.why()` | âœ… | Delegates to Provenance |
| `how()` | `DRS.how()` | âœ… | Delegates to Provenance |
| `paths()` | `DRS.paths()` | âœ… | Delegates to Provenance |
| `_compute_certainty_scores()` | `DRS._compute_certainty_scores()` | âœ… | Bug-fixed: per-element visited sets |
| `_compute_coverage_scores()` | `DRS._compute_coverage_scores()` | âœ… | Bitarray-based coverage |
| `rank_certainty()` | `DRS.rank_certainty()` | âœ… | Sort by descending certainty |
| `rank_coverage()` | `DRS.rank_coverage()` | âœ… | Sort by descending coverage |
| `print_tables()` | `DRS.print_tables()` | âœ… | Mode save/restore |
| `print_columns()` | `DRS.print_columns()` | âœ… | Deduped iteration |
| `pretty_print_columns()` | `DRS.pretty_print_columns()` | âœ… | Bug-fixed: added seen-set dedup |
| `visualize_provenance()` | `DRS.visualize_provenance()` | ðŸ”´ | Matplotlib, low priority |
| `print_tables_with_scores()` | `DRS.print_tables_with_scores()` | ðŸ”´ | Display helper, low priority |
| `print_columns_with_scores()` | `DRS.print_columns_with_scores()` | ðŸ”´ | Display helper, low priority |

---

## 10  `aurum_v2/models/provenance.py`

> **Legacy source**: `aurum_legacy/algebra.py` (class `Provenance`)

| v2 Method | Legacy Method | Status | Notes |
|---|---|---|---|
| `record()` | `Provenance.record()` | âœ… | Type-dispatch: NONEâ†’skip, SEARCHâ†’standalone, ALGEBRAâ†’synthetic origin+edges, elseâ†’hit+edges. Bug-fixed: `Hit` import added |
| `identify_leafs_and_heads()` | `Provenance.identify_leafs_and_heads()` | âœ… | Iterate nodes; no predecessorsâ†’leaf; no successorsâ†’head |
| `why()` | `Provenance.why()` | âœ… | `all_simple_paths` for all leafs |
| `how()` | `Provenance.how()` | âœ… | For each head, call `all_simple_paths` |
| `paths()` | `Provenance.paths()` | âœ… | If a in leafsâ†’paths to heads; if a in headsâ†’paths from leafs; elseâ†’stitch |
| `explain()` | `Provenance.explain()` | âœ… | Traverse pairs, format as human-readable string |

---

## 11  `aurum_v2/profiler/column_profiler.py`

> **Legacy source**: Java `ddprofiler/src/main/java/` â€” **NO Python legacy exists**
> Reimplemented from Java source in prior sessions.

| v2 Method | Legacy Java Class | Status | Notes |
|---|---|---|---|
| `detect_column_type()` | `PreAnalyzer.readRows()` | âœ… | >50% parseable as float â†’ `"N"`, else `"T"` |
| `compute_kmin_hash()` | `KMinHash` class | âœ… | Polynomial rolling hash, MERSENNE_PRIME, k=512 |
| `compute_cardinality()` | `CardinalityAnalyzer` | âœ… | Python `set()` (simpler than legacy HyperLogLog) |
| `compute_numeric_stats()` | `Range` + `RangeAnalyzer` | âœ… | min/max/avg/median/iqr via numpy |
| `compute_entities()` | `EntityAnalyzer` | âœ… | Uses spaCy NER (legacy used OpenNLP) |
| `profile_column()` | `Worker` pipeline | âœ… | Combines type + cardinality + minhash/stats/NER |
| `create_es_indices()` | `NativeElasticStore.initStore()` | âœ… | Creates `profile` + `text` indices with mappings |
| `run()` / `profile_all()` | `Conductor` + `Main` | âœ… | Iterates sources, dispatches workers |
| `index_profile()` | `NativeElasticStore` bulk | âœ… | Bulk-indexes profile + text docs |

> **Also**: `aurum_v2/profiler/source_readers.py` â€” âœ… fully implemented (CSV + JSON + DB readers)

---

## 12  Functions Missing from v2 Entirely

These exist in the legacy but have no v2 stub. Only items useful for the agent use case are listed:

| Legacy File | Function | Purpose | Port? |
|---|---|---|---|
| `modelstore/elasticstore.py` | `search_keywords_fuzzily()` | ES fuzzy match with `"fuzziness": "AUTO"` | **Yes** â€” useful search variant |
| `modelstore/elasticstore.py` | `get_all_fields_with(attr)` | Generic scroll with arbitrary attribute filter | **Maybe** â€” utility for extensibility |
| `algebra.py` | `suggest_schema()` | Feed columns through traverseâ†’union | âšª Low value for agent |
| `ddapi.py` | `keywords_search()` / batch variants | Batch keyword, schema, table name searches | **Maybe** â€” trivially built from existing `search()` |
| `ddapi.py` | `entity_search()` | Search by `KW_ENTITIES` | **Maybe** â€” depends on entity profiling |
| `ddapi.py` | `inclusion_dependency_to()` | `Relation.INCLUSION_DEPENDENCY` neighbor search | **Maybe** â€” _neighbor_search handles it already |

> **Note**: DoD ranking functions (`rank_join_graphs_by_key_likelihood`, `rank_fields_in_join_path`, `get_paths_for_tables`) now have stubs in `dod/dod.py` (Section 6).

---

## 13  Implementation Priority

### Wave 1 â€” Core Infrastructure âœ… DONE

| File | Status |
|---|---|
| `profiler/column_profiler.py` | âœ… All 9 methods implemented |
| `profiler/source_readers.py` | âœ… CSV + JSON + DB readers |
| `store/elastic_store.py` | âœ… All 9 methods + StoreHandler alias |
| `store/duck_store.py` | âœ… DuckDB alternative store |
| `graph/field_network.py` | âœ… All 20+ methods |
| `models/drs.py` | âœ… 17/20 methods (3 display stubs, low priority) |
| `models/hit.py` | âœ… NamedTuple |
| `models/relation.py` | âœ… Enum |
| `models/annotation.py` | âœ… Dataclass |

### Wave 2 â€” Query Engine âœ… DONE

| File | Status |
|---|---|
| `discovery/algebra.py` | âœ… All methods (search, traverse, set ops, convenience wrappers) |
| `discovery/api.py` | âœ… `init_system()` + `Helper` + `API(Algebra)` |
| `builder/network_builder.py` | âœ… All 4 build functions (TF-IDF, MinHash, content sim, schema sim). Bug-fixed. |
| `builder/coordinator.py` | âœ… Orchestration |
| `models/provenance.py` | âœ… All 6 methods (record, why, how, paths, explain, identify_leafs_and_heads) |
| `config.py` | âœ… |

### Wave 3 â€” Statistical Analysis (needed for DoD column comparison)

| File | Effort | Status |
|---|---|---|
| `builder/analysis.py` | Medium | ðŸ”´ 13 stubs. Not blocking â€” `network_builder.py` inlines its own logic. |

### Wave 4 â€” Join & Materialization (agent can answer multi-hop questions)

| File | Effort | Status |
|---|---|---|
| `dod/join_utils.py` | Medium | ðŸ”´ 15 stubs (InTreeNode âœ…) |
| `dod/dod.py` | Large | ðŸ”´ 15 stubs (enums âœ…) |
| `dod/view_analysis.py` | Small | ðŸ”´ 8 stubs (ViewClass enum âœ…) |

### Summary: 52 stubs remain, all in Waves 3-4

The discovery/search pipeline is **fully operational**. Remaining work is the materialization layer (DoD) and standalone analysis functions.
